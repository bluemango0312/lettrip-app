{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluemango0312/lettrip-app/blob/main/%EC%95%84%EC%9D%B4%ED%85%9C%EA%B8%B0%EB%B0%98%ED%98%91%EC%97%85%ED%95%84%ED%84%B0%EB%A7%81_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "ogdLg_UGfnL3",
        "outputId": "4d2c3ac9-10d5-4b6f-f43c-d5be5a956bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 9s 4s/step - loss: 932.7805\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 10s 4s/step - loss: 932.7805\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 10s 5s/step - loss: 932.7805\n",
            "Recommended items for user 10441490830:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-25e48c300d4f>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_item\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mitem_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msimilarity_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_user_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# .item() 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Item: {item_id}, Similarity Score: {similarity_score:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "csv_path = '/content/sample_data/data_60.csv'\n",
        "data = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "rating_mean = data['rating'].mean()\n",
        "data['rating_normalized'] = data['rating'] - rating_mean\n",
        "\n",
        "user_ids = data['userId'].unique()\n",
        "item_ids = data['placeName'].unique()\n",
        "\n",
        "user_id_to_idx = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
        "item_id_to_idx = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
        "\n",
        "num_users = len(user_ids)\n",
        "num_items = len(item_ids)\n",
        "rating_matrix = np.zeros((num_items, num_users))\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    user_idx = user_id_to_idx[row['userId']]\n",
        "    item_idx = item_id_to_idx[row['placeName']]\n",
        "    rating_matrix[item_idx, user_idx] = row['rating_normalized']\n",
        "\n",
        "item_similarity = cosine_similarity(rating_matrix)\n",
        "\n",
        "# 추천 모델 구성 - 케라스 Model 클래스 상속\n",
        "class ItemBasedRecommender(keras.Model):\n",
        "    def __init__(self, num_items, item_similarity):\n",
        "        super(ItemBasedRecommender, self).__init__()\n",
        "        self.item_similarity = self.add_weight(\"item_similarity\", shape=(num_items, num_items), initializer=tf.keras.initializers.Constant(item_similarity), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_idx = inputs  # Remove the unpacking\n",
        "        user_ratings = tf.gather(self.item_similarity, user_idx)\n",
        "        recommendations = tf.linalg.matmul(self.item_similarity, tf.expand_dims(user_ratings, axis=-1))\n",
        "        return tf.squeeze(recommendations, axis=-1)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "model = ItemBasedRecommender(num_items, item_similarity)\n",
        "\n",
        "# 모델 학습\n",
        "X_train = np.array([user_id_to_idx[user_id] for user_id in user_ids])\n",
        "y_train = rating_matrix.T  # 실제 평점 행렬을 사용하여 학습\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# 예측 결과 및 유사도 출력\n",
        "user_id = 10441490830\n",
        "test_user_idx = user_id_to_idx.get(user_id, None)\n",
        "if test_user_idx is not None:\n",
        "    recommendations2 = model([test_user_idx])\n",
        "    sorted_item = np.argsort(recommendations2)[::-1][:10]\n",
        "\n",
        "    print(f\"Recommended items for user {user_id}:\")\n",
        "    for item_idx in sorted_item:\n",
        "        item_id = item_ids[item_idx]\n",
        "        similarity_score = item_similarity[item_idx, test_user_idx].item()  # .item() 추가\n",
        "        print(f\"Item: {item_id}, Similarity Score: {similarity_score:.4f}\")\n",
        "else:\n",
        "    print(f\"User {user_id} not found in the data.\")\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "y_pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN6qUXwKDdBM5j3W6284XO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}